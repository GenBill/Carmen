import yfinance as yf
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
import pytz
import os
import pickle
from pathlib import Path
import time

from lut import INTRADAY_VOLUME_LUT, INTRADAY_VOLUME_HK, INTRADAY_VOLUME_A

# ç¼“å­˜ç›®å½•
CACHE_DIR = Path(__file__).parent / '.cache'
CACHE_DIR.mkdir(exist_ok=True)

# å…¨å±€å†…å­˜ç¼“å­˜ï¼š{symbol: (timestamp, hist_data)}
# åŒæ—¶æ”¯æŒæœ¬åœ°æ–‡ä»¶ç¼“å­˜ï¼Œé¿å…ç¨‹åºé‡å¯åé‡æ–°è·å–æ•°æ®
_DATA_CACHE = {}

# æŸåçš„è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆå¤šæ¬¡å¤±è´¥åä¸å†å°è¯•ï¼‰
broken_stock_symbols = []
try:
    broken_symbols_file = Path(__file__).parent.parent / 'broken_stock_symbols.txt'
    if broken_symbols_file.exists():
        with open(broken_symbols_file, 'r') as f:
            broken_stock_symbols = [line.strip() for line in f if line.strip()]
except:
    broken_stock_symbols = []

def calculate_rsi(prices, period=14, return_series=False):
    """
    è®¡ç®— RSI æŒ‡æ ‡ï¼ˆä½¿ç”¨ Wilder's Smoothing æ–¹æ³•ï¼Œä¸å¯Œé€”ç­‰ä¸»æµå¹³å°ä¸€è‡´ï¼‰
    
    Args:
        prices: ä»·æ ¼åºåˆ—ï¼ˆpandas Seriesï¼‰
        period: RSI å‘¨æœŸï¼Œé»˜è®¤ 14
        return_series: æ˜¯å¦è¿”å›æ•´ä¸ªåºåˆ—ï¼Œé»˜è®¤ Falseï¼ˆåªè¿”å›æœ€åä¸€ä¸ªå€¼ï¼‰
        
    Returns:
        float æˆ– Series: RSI å€¼æˆ–æ•´ä¸ª RSI åºåˆ—
    """
    # è®¡ç®—ä»·æ ¼å˜åŠ¨
    delta = prices.diff()
    
    # åˆ†ç¦»ä¸Šæ¶¨å’Œä¸‹è·Œ
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)
    
    # ä½¿ç”¨ Wilder's Smoothingï¼ˆå¨å°”å¾·å¹³æ»‘æ³•ï¼‰
    # è¿™ç­‰åŒäº EMAï¼Œalpha = 1/period
    # pandas ewm å‚æ•°ï¼šalpha = 1/periodï¼Œadjust=False è¡¨ç¤ºä½¿ç”¨é€’å½’è®¡ç®—
    avg_gain = gain.ewm(alpha=1/period, adjust=False).mean()
    avg_loss = loss.ewm(alpha=1/period, adjust=False).mean()
    
    # è®¡ç®— RS å’Œ RSI
    rs = avg_gain / avg_loss
    rsi = 100 - (100 / (1 + rs))
    
    if return_series:
        return rsi
    else:
        return rsi.iloc[-1] if not pd.isna(rsi.iloc[-1]) else None


def calculate_ema(prices, period, return_series=False):
    """
    è®¡ç®— EMA (æŒ‡æ•°ç§»åŠ¨å¹³å‡çº¿)
    
    Args:
        prices: ä»·æ ¼åºåˆ—ï¼ˆpandas Seriesï¼‰
        period: EMA å‘¨æœŸ
        return_series: æ˜¯å¦è¿”å›æ•´ä¸ªåºåˆ—ï¼Œé»˜è®¤ Falseï¼ˆåªè¿”å›æœ€åä¸€ä¸ªå€¼ï¼‰
        
    Returns:
        float æˆ– Series: EMA å€¼æˆ–æ•´ä¸ª EMA åºåˆ—
    """
    ema = prices.ewm(span=period, adjust=False).mean()
    
    if return_series:
        return ema
    else:
        return ema.iloc[-1] if not pd.isna(ema.iloc[-1]) else None


def calculate_macd(prices, fast=12, slow=26, signal=9):
    """
    è®¡ç®— MACD æŒ‡æ ‡
    
    Args:
        prices: ä»·æ ¼åºåˆ—ï¼ˆpandas Seriesï¼‰
        fast: å¿«çº¿å‘¨æœŸï¼Œé»˜è®¤ 12
        slow: æ…¢çº¿å‘¨æœŸï¼Œé»˜è®¤ 26
        signal: ä¿¡å·çº¿å‘¨æœŸï¼Œé»˜è®¤ 9
        
    Returns:
        dict: åŒ…å« dif(macd), dea(signal), histogram, dif_dea_slope çš„å­—å…¸
    """
    exp1 = prices.ewm(span=fast, adjust=False).mean()
    exp2 = prices.ewm(span=slow, adjust=False).mean()
    dif = exp1 - exp2  # DIFçº¿ï¼ˆå¿«çº¿-æ…¢çº¿ï¼‰
    dea = dif.ewm(span=signal, adjust=False).mean()  # DEAçº¿ï¼ˆDIFçš„ä¿¡å·çº¿ï¼‰
    histogram = dif - dea
    
    # è®¡ç®—DIFæ–œç‡ï¼ˆå½“æ—¥DIF - å‰ä¸€æ—¥DIFï¼‰
    dif_slope, dea_slope, dif_dea_slope = None, None, None
    if len(dif) >= 2 and not pd.isna(dif.iloc[-1]) and not pd.isna(dif.iloc[-2]):
        dif_slope = dif.iloc[-1] - dif.iloc[-2]
    if len(dea) >= 2 and not pd.isna(dea.iloc[-1]) and not pd.isna(dea.iloc[-2]):
        dea_slope = dea.iloc[-1] - dea.iloc[-2]
    if dif_slope != None and dea_slope != None:
        dif_dea_slope = round(dif_slope - dea_slope, 2)
    
    return {
        'dif': round(dif.iloc[-1], 2) if not pd.isna(dif.iloc[-1]) else None,
        'dea': round(dea.iloc[-1], 2) if not pd.isna(dea.iloc[-1]) else None,
        'histogram': round(histogram.iloc[-1], 2) if not pd.isna(histogram.iloc[-1]) else None,
        'dif_dea_slope': dif_dea_slope
    }


def is_intraday_data(trading_date_timestamp):
    """
    åˆ¤æ–­äº¤æ˜“æ—¥æ•°æ®æ˜¯å¦æ˜¯å½“æ—¥ç›˜ä¸­æ•°æ®
    
    Args:
        trading_date_timestamp: äº¤æ˜“æ—¥çš„æ—¶é—´æˆ³ï¼ˆpandas Timestampï¼Œå¸¦æ—¶åŒºï¼‰
        
    Returns:
        tuple: (is_today, current_et_time) - æ˜¯å¦æ˜¯ä»Šå¤©çš„æ•°æ®ï¼Œå½“å‰ç¾ä¸œæ—¶é—´
    """
    et_tz = pytz.timezone('America/New_York')
    
    # å°†äº¤æ˜“æ—¥æ—¶é—´æˆ³è½¬æ¢ä¸ºç¾ä¸œæ—¶é—´
    if trading_date_timestamp.tzinfo is None:
        # å¦‚æœæ²¡æœ‰æ—¶åŒºä¿¡æ¯ï¼Œå‡è®¾æ˜¯UTC
        trading_date_et = trading_date_timestamp.tz_localize('UTC').tz_convert(et_tz)
    else:
        trading_date_et = trading_date_timestamp.tz_convert(et_tz)
    
    # è·å–å½“å‰ç¾ä¸œæ—¶é—´
    current_et = datetime.now(et_tz)
    
    # æå–æ—¥æœŸéƒ¨åˆ†è¿›è¡Œæ¯”è¾ƒ
    trading_date_str = trading_date_et.strftime('%Y-%m-%d')
    current_date_str = current_et.strftime('%Y-%m-%d')
    
    is_today = (trading_date_str == current_date_str)
    
    return is_today, current_et

def is_market_time(current_et_time):
    """
    æ£€æŸ¥å½“å‰ETæ—¶é—´æ˜¯å¦åœ¨ç¾è‚¡äº¤æ˜“æ—¶é—´å†…ï¼ˆ9:30-16:00 ETï¼Œå…¨å¹´å›ºå®šï¼‰ã€‚
    
    Args:
        current_et_time (datetime): å·²è½¬æ¢ä¸ºETçš„datetimeå¯¹è±¡ï¼ˆæ— æ—¶åŒºæˆ–å¸¦ETæ—¶åŒºï¼‰ã€‚
    
    Returns:
        bool: æ˜¯å¦åœ¨äº¤æ˜“æ—¶é—´å†…ã€‚
    """
    # ç¾è‚¡äº¤æ˜“æ—¶é—´å›ºå®šä¸ºET 9:30-16:00ï¼ˆä¸å«å‘¨æœ«/å‡æœŸï¼Œæ­¤å‡½æ•°ä»…æŸ¥æ—¶é—´ï¼‰
    current_time_minutes = current_et_time.hour * 60 + current_et_time.minute
    market_open = 9 * 60 + 30
    market_close = 16 * 60
    
    return market_open <= current_time_minutes < market_close  # æ³¨æ„ï¼šæ”¶ç›˜ä¸å«16:00æœ¬èº«ï¼Œè‹¥éœ€å«å¯æ”¹<=

def estimate_full_day_volume_hka(current_volume, trading_date_timestamp, volume_lut=None, lunch_volume_multiplier=1.667):
    """
    æ¸¯è‚¡/Aè‚¡æˆäº¤é‡ä¼°ç®—ï¼ˆä¸“ç”¨å‡½æ•°ï¼‰
    æ¸¯è‚¡äº¤æ˜“æ—¶é—´ï¼šæ—©ç›˜ 9:30-12:00 CSTï¼Œåˆç›˜ 13:00-16:00 CST
    åˆä¼‘æ—¶é—´ï¼š12:00-13:00 CST
    
    Args:
        current_volume: å½“å‰æˆäº¤é‡
        trading_date_timestamp: äº¤æ˜“æ—¥çš„æ—¶é—´æˆ³ï¼ˆpandas Timestampï¼‰
        volume_lut: æˆäº¤é‡LUTè¡¨ï¼ŒNoneåˆ™ä½¿ç”¨é»˜è®¤è¡¨
        lunch_volume_multiplier: åˆä¼‘æœŸé—´æ—©ç›˜æˆäº¤é‡çš„å€ç‡ï¼ˆé»˜è®¤1.667ï¼‰
        
    Returns:
        int: ä¼°ç®—çš„å…¨å¤©æˆäº¤é‡
    """
    # ä½¿ç”¨åŒ—äº¬/é¦™æ¸¯æ—¶åŒºï¼ˆCST/HKTï¼ŒUTC+8ï¼‰
    cst_tz = pytz.timezone('Asia/Shanghai')
    
    # å°†äº¤æ˜“æ—¥æ—¶é—´æˆ³è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´
    if trading_date_timestamp.tzinfo is None:
        trading_date_cst = trading_date_timestamp.tz_localize('UTC').tz_convert(cst_tz)
    else:
        trading_date_cst = trading_date_timestamp.tz_convert(cst_tz)
    
    # è·å–å½“å‰åŒ—äº¬æ—¶é—´
    current_cst = datetime.now(cst_tz)
    
    # æå–æ—¥æœŸéƒ¨åˆ†è¿›è¡Œæ¯”è¾ƒ
    trading_date_str = trading_date_cst.strftime('%Y-%m-%d')
    current_date_str = current_cst.strftime('%Y-%m-%d')
    
    is_today = (trading_date_str == current_date_str)
    
    if not is_today:
        # ä¸æ˜¯ä»Šå¤©çš„æ•°æ®ï¼Œç›´æ¥è¿”å›åŸå€¼ï¼ˆè¿™æ˜¯å·²æ”¶ç›˜çš„å®Œæ•´æ•°æ®ï¼‰
        return current_volume
    
    # è·å–å½“å‰æ—¶é—´ï¼ˆCSTï¼‰
    current_time_minutes = current_cst.hour * 60 + current_cst.minute
    
    # æ¸¯è‚¡äº¤æ˜“æ—¶é—´æ®µï¼ˆCSTï¼ŒåŒ—äº¬æ—¶é—´ï¼‰
    # æ—©ç›˜ï¼š9:30-12:00ï¼ˆ150åˆ†é’Ÿï¼‰
    # åˆä¼‘ï¼š12:00-13:00ï¼ˆ60åˆ†é’Ÿï¼‰
    # åˆç›˜ï¼š13:00-16:00ï¼ˆ180åˆ†é’Ÿï¼‰
    # æ”¶ç›˜åï¼š16:00-æ¬¡æ—¥9:30
    
    market_open_am = 9 * 60 + 30  # 9:30 CST
    market_close_am = 12 * 60      # 12:00 CST
    lunch_break_start = 12 * 60    # 12:00 CST
    lunch_break_end = 13 * 60      # 13:00 CST
    market_open_pm = 13 * 60       # 13:00 CST
    market_close_pm = 16 * 60      # 16:00 CST
    
    # åˆ¤æ–­å½“å‰æ—¶é—´
    # æ³¨æ„ï¼šè„šæœ¬ä»…åœ¨åˆä¼‘æ—¶é—´å’Œæ”¶ç›˜åè¿è¡Œ
    if lunch_break_start <= current_time_minutes < lunch_break_end:
        # åˆä¼‘æ—¶æ®µï¼ˆ12:00-13:00 CSTï¼‰ï¼šæ—©ç›˜æˆäº¤é‡ Ã— å›ºå®šå€ç‡
        estimated_volume = int(current_volume * lunch_volume_multiplier)
        return estimated_volume
    elif current_time_minutes >= market_close_pm:
        # æ”¶ç›˜åï¼ˆ16:00 CSTä¹‹åï¼‰ï¼šç›´æ¥ä½¿ç”¨å½“å‰æˆäº¤é‡ï¼ˆå·²æ˜¯å…¨å¤©æˆäº¤é‡ï¼‰
        return current_volume
    else:
        # äº¤æ˜“æ—¶æ®µï¼ˆç†è®ºä¸Šä¸ä¼šåˆ°è¾¾è¿™é‡Œï¼Œå› ä¸ºè„šæœ¬ä¸åœ¨æ­¤æ—¶è¿è¡Œï¼‰
        # ä½†å¦‚æœæ„å¤–è°ƒç”¨ï¼Œä½¿ç”¨LUTä¼°ç®—
        if volume_lut is None:
            volume_lut = INTRADAY_VOLUME_HK
        
        current_time_str = current_cst.strftime('%H:%M')
        
        # æŸ¥æ‰¾æœ€æ¥è¿‘çš„æ—¶é—´ç‚¹
        time_keys = sorted(volume_lut.keys())
        selected_ratio = None
        
        for time_key in time_keys:
            if current_time_str <= time_key:
                selected_ratio = volume_lut[time_key]
                break
        
        # å¦‚æœå½“å‰æ—¶é—´è¶…è¿‡æœ€åä¸€ä¸ªæ—¶é—´ç‚¹ï¼Œä½¿ç”¨1.0
        if selected_ratio is None:
            selected_ratio = 1.0
        
        # ä¼°ç®—å…¨å¤©æˆäº¤é‡
        if selected_ratio > 0:
            estimated_volume = int(current_volume / selected_ratio)
            return estimated_volume
        else:
            return current_volume


def estimate_full_day_volume(current_volume, trading_date_timestamp, volume_lut=None):
    """
    ç¾è‚¡æˆäº¤é‡ä¼°ç®—ï¼ˆåŸæœ‰å‡½æ•°ï¼‰
    æ ¹æ®ç›˜ä¸­å½“å‰æ—¶é—´å’Œæˆäº¤é‡ä¼°ç®—å…¨å¤©æˆäº¤é‡
    åªåœ¨ç¡®è®¤æ˜¯å½“æ—¥ç›˜ä¸­æ•°æ®æ—¶æ‰ä¼°ç®—ï¼Œå¦åˆ™è¿”å›åŸå€¼
    
    Args:
        current_volume: å½“å‰æˆäº¤é‡
        trading_date_timestamp: äº¤æ˜“æ—¥çš„æ—¶é—´æˆ³ï¼ˆpandas Timestampï¼‰
        volume_lut: æˆäº¤é‡LUTè¡¨ï¼ŒNoneåˆ™ä½¿ç”¨é»˜è®¤è¡¨
        
    Returns:
        int: ä¼°ç®—çš„å…¨å¤©æˆäº¤é‡ï¼Œå¦‚æœä¸æ˜¯ç›˜ä¸­æ•°æ®åˆ™è¿”å›åŸå€¼
    """
    # åˆ¤æ–­æ˜¯å¦æ˜¯å½“æ—¥ç›˜ä¸­æ•°æ®
    is_today, current_et_time = is_intraday_data(trading_date_timestamp)
    
    if not is_today:
        # ä¸æ˜¯ä»Šå¤©çš„æ•°æ®ï¼Œç›´æ¥è¿”å›åŸå€¼ï¼ˆè¿™æ˜¯å·²æ”¶ç›˜çš„å®Œæ•´æ•°æ®ï¼‰
        return current_volume
    
    if not is_market_time(current_et_time):
        # ä¸åœ¨äº¤æ˜“æ—¶é—´å†…ï¼Œè¿”å›åŸå€¼
        return current_volume
    
    # åœ¨ç›˜ä¸­ï¼Œè¿›è¡Œä¼°ç®—
    if volume_lut is None:
        volume_lut = INTRADAY_VOLUME_LUT
    
    current_time_str = current_et_time.strftime('%H:%M')
    
    # æŸ¥æ‰¾æœ€æ¥è¿‘çš„æ—¶é—´ç‚¹
    time_keys = sorted(volume_lut.keys())
    selected_ratio = None
    
    for time_key in time_keys:
        if current_time_str <= time_key:
            selected_ratio = volume_lut[time_key]
            break
    
    # å¦‚æœå½“å‰æ—¶é—´è¶…è¿‡æœ€åä¸€ä¸ªæ—¶é—´ç‚¹ï¼Œä½¿ç”¨1.0
    if selected_ratio is None:
        selected_ratio = 1.0
    
    # é¿å…é™¤ä»¥0
    if selected_ratio > 0:
        estimated_volume = int(current_volume / selected_ratio)
        return estimated_volume
    else:
        return current_volume


def _get_cache_file_path(symbol: str) -> Path:
    """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
    return CACHE_DIR / f"{symbol}.pkl"


def _load_cache_from_file(symbol: str):
    """ä»æœ¬åœ°æ–‡ä»¶åŠ è½½ç¼“å­˜"""
    cache_file = _get_cache_file_path(symbol)
    if cache_file.exists():
        try:
            with open(cache_file, 'rb') as f:
                cached_time, hist_data = pickle.load(f)
                return cached_time, hist_data
        except Exception as e:
            print(f"åŠ è½½ç¼“å­˜æ–‡ä»¶å¤±è´¥ {symbol}: {e}")
            return None
    return None


def _save_cache_to_file(symbol: str, cached_time, hist_data):
    """ä¿å­˜ç¼“å­˜åˆ°æœ¬åœ°æ–‡ä»¶"""
    cache_file = _get_cache_file_path(symbol)
    try:
        with open(cache_file, 'wb') as f:
            pickle.dump((cached_time, hist_data), f)
    except Exception as e:
        print(f"ä¿å­˜ç¼“å­˜æ–‡ä»¶å¤±è´¥ {symbol}: {e}")


def _get_expected_latest_trading_date(current_et):
    """
    è®¡ç®—é¢„æœŸçš„æœ€æ–°äº¤æ˜“æ—¥æ—¥æœŸï¼ˆä¸å«èŠ‚å‡æ—¥ï¼Œä»…æ’é™¤å‘¨æœ«ï¼‰
    
    Args:
        current_et: ç¾ä¸œå½“å‰æ—¶é—´ (datetime with timezone)
    
    Returns:
        date: é¢„æœŸçš„æœ€æ–°äº¤æ˜“æ—¥æ—¥æœŸ
    """
    current_date = current_et.date()
    current_hour_minute = current_et.hour * 60 + current_et.minute
    
    # ç¾è‚¡æ”¶ç›˜æ—¶é—´ 16:00 (ä½¿ç”¨å®é™…æ”¶ç›˜æ—¶é—´ï¼Œä¸æ˜¯ç¼“å†²æ—¶é—´)
    market_close_time = 16 * 60  # 16:00
    is_weekday = current_et.weekday() < 5  # å‘¨ä¸€åˆ°å‘¨äº”
    
    if is_weekday and current_hour_minute >= market_close_time:
        # äº¤æ˜“æ—¥å·²æ”¶ç›˜ â†’ æ•°æ®åº”è¯¥æ˜¯ä»Šå¤©
        return current_date
    else:
        # ç›˜å‰ æˆ– å‘¨æœ« â†’ æ•°æ®åº”è¯¥æ˜¯ä¸Šä¸€ä¸ªäº¤æ˜“æ—¥
        # å›æº¯æ‰¾åˆ°ä¸Šä¸€ä¸ªäº¤æ˜“æ—¥
        check_date = current_date - timedelta(days=1)
        while check_date.weekday() >= 5:  # è·³è¿‡å‘¨æœ«
            check_date -= timedelta(days=1)
        return check_date


def _is_cache_valid_smart(cached_time, cached_hist, cache_minutes, ignore_expiry=False):
    """
    æ™ºèƒ½ç¼“å­˜æœ‰æ•ˆæ€§æ£€æŸ¥ï¼ˆåŸºäºæ•°æ®æœ€æ–°æ—¥æœŸå’Œå¸‚åœºçŠ¶æ€ï¼‰
    
    æ ¸å¿ƒæ€æƒ³ï¼š
    - è‚¡ç¥¨ä»·æ ¼åªåœ¨ç›˜ä¸­å˜åŒ–
    - ç¼“å­˜åº”è¯¥åŸºäº"æ•°æ®çš„æœ€æ–°äº¤æ˜“æ—¥"è€Œä¸æ˜¯"ç¼“å­˜ä¿å­˜æ—¶é—´"
    
    Args:
        cached_time: ç¼“å­˜ä¿å­˜æ—¶é—´
        cached_hist: ç¼“å­˜çš„å†å²æ•°æ®
        cache_minutes: ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆåˆ†é’Ÿï¼‰
        ignore_expiry: æ˜¯å¦å¿½ç•¥è¿‡æœŸï¼ˆç¦»çº¿æ¨¡å¼ï¼‰
        
    Returns:
        bool: ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
    """
    if ignore_expiry:
        return True
    
    now = datetime.now()
    et_tz = pytz.timezone('America/New_York')
    
    # å°†ç¼“å­˜æ—¶é—´è½¬æ¢ä¸ºç¾ä¸œæ—¶é—´
    if cached_time.tzinfo is None:
        cached_time_et = pytz.utc.localize(cached_time).astimezone(et_tz)
    else:
        cached_time_et = cached_time.astimezone(et_tz)
    
    current_et = datetime.now(et_tz)
    
    # åˆ¤æ–­ç¼“å­˜ä¿å­˜æ—¶é—´æ˜¯å¦åœ¨ç›˜ä¸­ï¼ˆ9:30-16:30 ETï¼Œå«ç›˜å30åˆ†é’Ÿç¼“å†²æœŸï¼‰
    cached_hour_minute = cached_time_et.hour * 60 + cached_time_et.minute
    market_open = 9 * 60 + 30   # 9:30
    market_close = 16 * 60 + 30  # 16:30ï¼ˆç›˜å30åˆ†é’Ÿç¼“å†²ï¼Œå› APIæœ‰5-10åˆ†é’Ÿå»¶è¿Ÿï¼‰
    was_cached_during_market = market_open <= cached_hour_minute < market_close
    
    # å¦‚æœç¼“å­˜æ—¶é—´æˆ³åœ¨ç›˜ä¸­ï¼Œä½¿ç”¨ä¼ ç»Ÿçš„æ—¶é—´åˆ¤æ–­ï¼ˆçŸ­ç¼“å­˜ï¼‰
    if was_cached_during_market:
        cache_age_minutes = (now - cached_time).total_seconds() / 60
        return cache_age_minutes < cache_minutes
    
    # å¦‚æœç¼“å­˜æ—¶é—´æˆ³ä¸åœ¨ç›˜ä¸­ï¼ˆç›˜å‰/ç›˜å/å‘¨æœ«ï¼‰ï¼Œæ£€æŸ¥æ•°æ®çš„æœ€æ–°æ—¥æœŸ
    if cached_hist is None or cached_hist.empty:
        return False
    
    # è·å–ç¼“å­˜æ•°æ®çš„æœ€åäº¤æ˜“æ—¥
    last_data_date = cached_hist.index[-1]
    if last_data_date.tzinfo is None:
        last_data_date_et = pytz.utc.localize(last_data_date).astimezone(et_tz)
    else:
        last_data_date_et = last_data_date.astimezone(et_tz)
    
    # åˆ¤æ–­å½“å‰æ˜¯å¦åœ¨ç›˜ä¸­ï¼ˆå«ç›˜å30åˆ†é’Ÿç¼“å†²æœŸï¼‰
    current_hour_minute = current_et.hour * 60 + current_et.minute
    is_market_open_now = (market_open <= current_hour_minute < market_close and 
                          current_et.weekday() < 5)
    
    if is_market_open_now:
        # å½“å‰åœ¨ç›˜ä¸­ï¼Œéœ€è¦å®æ—¶æ•°æ®
        # æ£€æŸ¥æ•°æ®æ˜¯å¦æ˜¯ä»Šå¤©çš„ï¼Œä¸”ç¼“å­˜ä¸è¶…è¿‡æŒ‡å®šæ—¶é—´
        current_date = current_et.date()
        last_data_only_date = last_data_date_et.date()
        
        if last_data_only_date >= current_date:
            # æ•°æ®æ˜¯ä»Šå¤©çš„ï¼Œæ£€æŸ¥ç¼“å­˜å¹´é¾„
            cache_age_minutes = (now - cached_time).total_seconds() / 60
            return cache_age_minutes < cache_minutes
        else:
            # æ•°æ®ä¸æ˜¯ä»Šå¤©çš„ï¼Œéœ€è¦åˆ·æ–°
            return False
    else:
        # å½“å‰ä¸åœ¨ç›˜ä¸­ï¼ˆç›˜å‰/ç›˜å/å‘¨æœ«ï¼‰ï¼Œéœ€è¦æœ€æ–°äº¤æ˜“æ—¥æ•°æ®
        last_data_only_date = last_data_date_et.date()
        expected_date = _get_expected_latest_trading_date(current_et)
        
        # ã€å…³é”®ä¿®å¤ã€‘å¿…é¡»å…ˆæ£€æŸ¥æ•°æ®æ—¥æœŸæ˜¯å¦æ˜¯æœ€æ–°äº¤æ˜“æ—¥
        if last_data_only_date < expected_date:
            # æ•°æ®ä¸æ˜¯æœ€æ–°äº¤æ˜“æ—¥ï¼Œç¼“å­˜æ— æ•ˆï¼Œå¿…é¡»åˆ·æ–°
            return False
        
        # æ•°æ®æ˜¯æœ€æ–°äº¤æ˜“æ—¥çš„ï¼Œå†æ£€æŸ¥ç¼“å­˜å¹´é¾„
        cache_age_minutes = (now - cached_time).total_seconds() / 60
        return cache_age_minutes < cache_minutes


def _load_from_cache(symbol: str, cache_minutes=5, ignore_expiry=False):
    """
    ä»ç¼“å­˜åŠ è½½æ•°æ®ï¼ˆå…¬å…±å‡½æ•°ï¼‰
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        cache_minutes: ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆåˆ†é’Ÿï¼‰
        ignore_expiry: æ˜¯å¦å¿½ç•¥è¿‡æœŸæ—¶é—´ï¼ˆç¦»çº¿æ¨¡å¼ç”¨ï¼‰
        
    Returns:
        tuple: (hist_data, cache_source) æˆ– (None, None)
    """
    now = datetime.now()
    cache_key = symbol
    
    # 1. æ£€æŸ¥å†…å­˜ç¼“å­˜
    if cache_key in _DATA_CACHE:
        cached_time, cached_hist = _DATA_CACHE[cache_key]
        
        if _is_cache_valid_smart(cached_time, cached_hist, cache_minutes, ignore_expiry):
            return cached_hist, "å†…å­˜"
    
    # 2. æ£€æŸ¥æ–‡ä»¶ç¼“å­˜
    file_cache = _load_cache_from_file(symbol)
    if file_cache:
        cached_time, cached_hist = file_cache
        
        if _is_cache_valid_smart(cached_time, cached_hist, cache_minutes, ignore_expiry):
            # åŠ è½½åˆ°å†…å­˜ç¼“å­˜
            _DATA_CACHE[cache_key] = (cached_time, cached_hist)
            return cached_hist, "æ–‡ä»¶"
    
    return None, None


def _calculate_indicators_from_hist(hist, symbol, rsi_period, macd_fast, macd_slow, 
                                    macd_signal, avg_volume_days, volume_lut):
    """
    ä»å†å²æ•°æ®è®¡ç®—æ‰€æœ‰æŒ‡æ ‡ï¼ˆå…¬å…±è®¡ç®—é€»è¾‘ï¼‰
    
    Args:
        hist: å†å²æ•°æ®DataFrame
        symbol: è‚¡ç¥¨ä»£ç 
        å…¶ä»–å‚æ•°: æŠ€æœ¯æŒ‡æ ‡å‚æ•°
        
    Returns:
        dict: åŒ…å«æ‰€æœ‰è®¡ç®—ç»“æœçš„å­—å…¸
    """
    if hist.empty or len(hist) < avg_volume_days + 1:
        return None
    
    # è·å–æœ€åä¸€ä¸ªäº¤æ˜“æ—¥æ•°æ®ï¼ˆå½“æ—¥æˆ–æœ€è¿‘äº¤æ˜“æ—¥ï¼‰
    last_trading_day = hist.iloc[-1]
    
    # æ£€æŸ¥å…³é”®æ•°æ®æœ‰æ•ˆæ€§
    if pd.isna(last_trading_day['Close']):
        return None

    trading_date_timestamp = hist.index[-1]
    trading_date = trading_date_timestamp.strftime('%Y-%m-%d')
    
    # è®¡ç®—è¿‡å» N æ—¥å¹³å‡æˆäº¤é‡ï¼ˆæ˜ç¡®æ’é™¤å½“æ—¥ï¼Œå³æœ€åä¸€ä¸ªäº¤æ˜“æ—¥ï¼‰
    if len(hist) >= avg_volume_days + 1:
        avg_volume = hist.iloc[-(avg_volume_days+1):-1]['Volume'].mean()
    else:
        avg_volume = hist.iloc[:-1]['Volume'].mean()
    
    if pd.isna(avg_volume):
        avg_volume = 0

    # å½“æ—¥æˆäº¤é‡
    current_volume = last_trading_day['Volume']
    if pd.isna(current_volume):
        current_volume = 0
    
    # åˆ¤æ–­æ˜¯æ¸¯è‚¡/Aè‚¡è¿˜æ˜¯ç¾è‚¡
    is_hk_stock = symbol.endswith('.HK')
    is_a_stock = symbol.endswith('.SS') or symbol.endswith('.SZ')
    
    # ä¼°ç®—å…¨å¤©æˆäº¤é‡ï¼ˆåªåœ¨ç¡®è®¤æ˜¯å½“æ—¥ç›˜ä¸­æ•°æ®æ—¶æ‰ä¼°ç®—ï¼‰
    if is_hk_stock:
        estimated_volume = estimate_full_day_volume_hka(current_volume, trading_date_timestamp, volume_lut=INTRADAY_VOLUME_HK)
    elif is_a_stock:
        estimated_volume = estimate_full_day_volume_hka(current_volume, trading_date_timestamp, volume_lut=INTRADAY_VOLUME_A)
    else:
        estimated_volume = estimate_full_day_volume(current_volume, trading_date_timestamp, volume_lut=volume_lut)
    
    # è®¡ç®— RSIï¼ˆè·å–å®Œæ•´åºåˆ—ä»¥ä¾¿æå–å‰ä¸€æ—¥æ•°æ®ï¼‰
    rsi_series = calculate_rsi(hist['Close'], period=rsi_period, return_series=True)
    rsi = rsi_series.iloc[-1] if not pd.isna(rsi_series.iloc[-1]) else None
    rsi_prev = None
    if len(rsi_series) >= 2 and not pd.isna(rsi_series.iloc[-2]):
        rsi_prev = rsi_series.iloc[-2]
    
    # è®¡ç®— MACD
    macd_data = calculate_macd(hist['Close'], fast=macd_fast, slow=macd_slow, signal=macd_signal)
    
    # è®¡ç®— EMA æŒ‡æ ‡ï¼ˆè·å–å®Œæ•´åºåˆ—ä»¥ä¾¿æå–å‰ä¸€æ—¥æ•°æ®ï¼‰
    ema_12_series = calculate_ema(hist['Close'], period=12, return_series=True)
    ema_144_series = calculate_ema(hist['Close'], period=144, return_series=True)
    
    ema_12 = ema_12_series.iloc[-1] if not pd.isna(ema_12_series.iloc[-1]) else None
    ema_144 = ema_144_series.iloc[-1] if not pd.isna(ema_144_series.iloc[-1]) else None
    
    # è·å–å‰ä¸€æ—¥ EMA æ•°æ®
    ema_12_prev = None
    ema_144_prev = None
    if len(ema_12_series) >= 2 and not pd.isna(ema_12_series.iloc[-2]):
        ema_12_prev = ema_12_series.iloc[-2]
    if len(ema_144_series) >= 2 and not pd.isna(ema_144_series.iloc[-2]):
        ema_144_prev = ema_144_series.iloc[-2]
    
    return {
        'symbol': symbol,
        'date': trading_date,
        'open': round(last_trading_day['Open'], 2),
        'close': round(last_trading_day['Close'], 2),
        'volume': int(current_volume),
        'estimated_volume': estimated_volume,
        'avg_volume': int(avg_volume),
        'rsi': round(rsi, 2) if rsi else None,
        'rsi_prev': round(rsi_prev, 2) if rsi_prev else None,
        'dif': macd_data['dif'],
        'dea': macd_data['dea'],
        'macd_histogram': macd_data['histogram'],
        'dif_dea_slope': macd_data['dif_dea_slope'],
        'ema_12': round(ema_12, 2) if ema_12 else None,
        'ema_144': round(ema_144, 2) if ema_144 else None,
        'ema_12_prev': round(ema_12_prev, 2) if ema_12_prev else None,
        'ema_144_prev': round(ema_144_prev, 2) if ema_144_prev else None
    }


def get_stock_data_offline(symbol: str, rsi_period=14, macd_fast=12, macd_slow=26, macd_signal=9, 
                           avg_volume_days=8, volume_lut=None, use_cache=True, cache_minutes=5):
    """
    ç¦»çº¿æ¨¡å¼ï¼šä»…ä»ç¼“å­˜è¯»å–æ•°æ®ï¼Œä¸è°ƒç”¨APIï¼ˆå¿½ç•¥ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼‰
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        rsi_period: RSI å‘¨æœŸï¼Œé»˜è®¤ 14
        macd_fast: MACD å¿«çº¿å‘¨æœŸï¼Œé»˜è®¤ 12
        macd_slow: MACD æ…¢çº¿å‘¨æœŸï¼Œé»˜è®¤ 26
        macd_signal: MACD ä¿¡å·çº¿å‘¨æœŸï¼Œé»˜è®¤ 9
        avg_volume_days: å¹³å‡æˆäº¤é‡è®¡ç®—å¤©æ•°ï¼Œé»˜è®¤ 8
        volume_lut: è‡ªå®šä¹‰æˆäº¤é‡ä¼°ç®—LUTè¡¨ï¼ŒNoneåˆ™ä½¿ç”¨é»˜è®¤è¡¨
        use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜ï¼ˆç¦»çº¿æ¨¡å¼å›ºå®šä¸ºTrueï¼‰
        cache_minutes: å¿½ç•¥ï¼ˆç¦»çº¿æ¨¡å¼ä¸æ£€æŸ¥è¿‡æœŸï¼‰
        
    Returns:
        dict: åŒ…å«æ‰€æœ‰æ•°æ®çš„å­—å…¸ï¼Œç¼“å­˜ä¸å­˜åœ¨è¿”å› None
    """
    try:
        # ä»ç¼“å­˜åŠ è½½ï¼ˆå¿½ç•¥è¿‡æœŸæ—¶é—´ï¼‰
        hist, cache_source = _load_from_cache(symbol, cache_minutes=0, ignore_expiry=True)
        
        if hist is None:
            # ç¦»çº¿æ¨¡å¼ä¸‹ç¼“å­˜ä¸å­˜åœ¨åˆ™è¿”å›None
            return None
        
        # ä½¿ç”¨å†å²æ•°æ®è®¡ç®—æŒ‡æ ‡ï¼ˆå…¬å…±è®¡ç®—é€»è¾‘ï¼‰
        return _calculate_indicators_from_hist(
            hist, symbol, rsi_period, macd_fast, macd_slow,
            macd_signal, avg_volume_days, volume_lut
        )
    except KeyboardInterrupt:
        raise
    except Exception as e:
        print(f"âš ï¸  ç¦»çº¿æ¨¡å¼è·å– {symbol} æ•°æ®æ—¶å‡ºé”™: {e}")
        return None


def batch_download_stocks(symbols: list, use_cache=True, cache_minutes=5, batch_size=50, period="1y"):
    """
    æ‰¹é‡ä¸‹è½½è‚¡ç¥¨æ•°æ®ï¼ˆä½¿ç”¨ yfinance çš„å¤šçº¿ç¨‹åŠ é€Ÿï¼‰

    Args:
        symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜ï¼Œé»˜è®¤ True
        cache_minutes: ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆåˆ†é’Ÿï¼‰ï¼Œé»˜è®¤ 5åˆ†é’Ÿ
        batch_size: æ¯æ‰¹ä¸‹è½½çš„è‚¡ç¥¨æ•°é‡ï¼Œé»˜è®¤ 50
        period: ä¸‹è½½æ•°æ®çš„æ—¶é—´å‘¨æœŸï¼Œé»˜è®¤ "1y"

    Returns:
        None
    """
    if not symbols:
        return

    # è¿‡æ»¤æ‰æŸåçš„è‚¡ç¥¨ä»£ç 
    valid_symbols = [s for s in symbols if s not in broken_stock_symbols]
    if not valid_symbols:
        return

    # æ£€æŸ¥ç¼“å­˜ï¼Œåªä¸‹è½½æ²¡æœ‰æœ‰æ•ˆç¼“å­˜çš„è‚¡ç¥¨
    symbols_to_download = []
    for symbol in valid_symbols:
        if use_cache:
            hist, _ = _load_from_cache(symbol, cache_minutes, ignore_expiry=False)
            if hist is None:
                symbols_to_download.append(symbol)
        else:
            symbols_to_download.append(symbol)

    if not symbols_to_download:
        # print("âœ… æ‰€æœ‰è‚¡ç¥¨ç¼“å­˜å‡æœ‰æ•ˆï¼Œæ— éœ€é‡æ–°ä¸‹è½½")
        return
    # if use_cache:
    #     print(f"ğŸ“‚ ç¼“å­˜ç›®å½•: {CACHE_DIR.resolve()}")

    # åˆ†æ‰¹ä¸‹è½½ï¼Œé¿å…å•æ¬¡è¯·æ±‚è¿‡å¤š
    total_batches = (len(symbols_to_download) + batch_size - 1) // batch_size
    try:
        from tqdm import tqdm
        batch_iter = tqdm(
            range(0, len(symbols_to_download), batch_size),
            desc="ğŸ“¥ æ‰¹é‡ä¸‹è½½è‚¡ç¥¨æ•°æ®",
            total=total_batches,
            unit="batch"
        )
    except ImportError:
        # å¦‚æœæ²¡æœ‰å®‰è£… tqdmï¼Œä½¿ç”¨æ™®é€š range
        batch_iter = range(0, len(symbols_to_download), batch_size)

    for i in batch_iter:
        batch = symbols_to_download[i:i + batch_size]
        if not batch:
            continue

        try:
            # ä½¿ç”¨ yf.download æ‰¹é‡ä¸‹è½½ï¼Œè‡ªåŠ¨å¤šçº¿ç¨‹åŠ é€Ÿ
            # å¿…é¡»æŒ‡å®š group_by='ticker' æ‰èƒ½ä½¿ Ticker ä½œä¸ºç¬¬ä¸€å±‚ç´¢å¼•ï¼Œæ–¹ä¾¿æŒ‰è‚¡ç¥¨åˆ‡åˆ†
            hist_batch = yf.download(batch, period=period, progress=False, auto_adjust=False, threads=True, group_by='ticker')

            if hist_batch.empty:
                print(f"âš ï¸  æ‰¹é‡ä¸‹è½½è¿”å›ç©ºæ•°æ®ï¼Œæ‰¹æ¬¡: {i//batch_size + 1}")
                continue

            # å¤„ç†è¿”å›çš„æ•°æ®æ ¼å¼
            # yf.download è¿”å›æ ¼å¼ï¼š
            # - å•åªè‚¡ç¥¨ï¼šå¯èƒ½è¿”å›å•å±‚ç´¢å¼•æˆ– MultiIndexï¼ˆå–å†³äºç‰ˆæœ¬ï¼‰
            # - å¤šåªè‚¡ç¥¨ï¼šè¿”å› MultiIndex (ticker, column)
            if isinstance(hist_batch.columns, pd.MultiIndex):
                # MultiIndexï¼šæŒ‰ ticker æ‹†åˆ†
                # è·å–æ‰€æœ‰ tickerï¼ˆç¬¬ä¸€å±‚ç´¢å¼•ï¼‰
                tickers_in_data = hist_batch.columns.get_level_values(0).unique().tolist()
                for symbol in batch:
                    if symbol in tickers_in_data:
                        try:
                            hist = hist_batch[symbol].copy()
                            if not hist.empty:
                                # æ›´æ–°ç¼“å­˜
                                # ç¡®ä¿æ ¼å¼å¯¹é½ï¼š(timestamp, dataframe)
                                if use_cache:
                                    now = datetime.now()
                                    _DATA_CACHE[symbol] = (now, hist)
                                    _save_cache_to_file(symbol, now, hist)
                        except Exception as e:
                            print(f"âš ï¸  å¤„ç† {symbol} æ•°æ®æ—¶å‡ºé”™: {e}")
                            continue
            else:
                # å•å±‚ç´¢å¼•ï¼šåªæœ‰ä¸€åªè‚¡ç¥¨çš„æƒ…å†µ
                if len(batch) == 1:
                    symbol = batch[0]
                    if not hist_batch.empty:
                        if use_cache:
                            now = datetime.now()
                            _DATA_CACHE[symbol] = (now, hist_batch)
                            _save_cache_to_file(symbol, now, hist_batch)
                else:
                    # å¤šåªè‚¡ç¥¨ä½†è¿”å›å•å±‚ç´¢å¼•ï¼ˆå¼‚å¸¸æƒ…å†µï¼Œå¯èƒ½æ‰€æœ‰è‚¡ç¥¨éƒ½ä¸‹è½½å¤±è´¥ï¼‰
                    print(f"âš ï¸  æ‰¹é‡ä¸‹è½½è¿”å›å¼‚å¸¸æ ¼å¼ï¼Œæ‰¹æ¬¡å¤§å°: {len(batch)}")

            # é¿å…è¿‡äºé¢‘ç¹çš„APIè°ƒç”¨
            if i + batch_size < len(symbols_to_download):
                time.sleep(0.01)

        except Exception as e:
            print(f"âš ï¸  æ‰¹é‡ä¸‹è½½å¤±è´¥ (æ‰¹æ¬¡ {i//batch_size + 1}): {e}")
            continue
    return


def get_stock_data(symbol: str, rsi_period=14, macd_fast=12, macd_slow=26, macd_signal=9, 
                   avg_volume_days=8, volume_lut=None, use_cache=True, cache_minutes=5):
    """
    è·å–è‚¡ç¥¨çš„å…¨é¢æ•°æ®ï¼ŒåŒ…æ‹¬ä»·æ ¼ã€æˆäº¤é‡å’ŒæŠ€æœ¯æŒ‡æ ‡
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        rsi_period: RSI å‘¨æœŸï¼Œé»˜è®¤ 14
        macd_fast: MACD å¿«çº¿å‘¨æœŸï¼Œé»˜è®¤ 12
        macd_slow: MACD æ…¢çº¿å‘¨æœŸï¼Œé»˜è®¤ 26
        macd_signal: MACD ä¿¡å·çº¿å‘¨æœŸï¼Œé»˜è®¤ 9
        avg_volume_days: å¹³å‡æˆäº¤é‡è®¡ç®—å¤©æ•°ï¼Œé»˜è®¤ 8
        volume_lut: è‡ªå®šä¹‰æˆäº¤é‡ä¼°ç®—LUTè¡¨ï¼ŒNoneåˆ™ä½¿ç”¨é»˜è®¤è¡¨
        use_cache: æ˜¯å¦ä½¿ç”¨æœ¬åœ°ç¼“å­˜ï¼Œé»˜è®¤ True
        cache_minutes: ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆåˆ†é’Ÿï¼‰ï¼Œé»˜è®¤ 5åˆ†é’Ÿ
        offline_mode: æ˜¯å¦ç¦»çº¿æ¨¡å¼ï¼Œé»˜è®¤ False
        
    Returns:
        dict: åŒ…å«æ‰€æœ‰æ•°æ®çš„å­—å…¸ï¼Œå¤±è´¥è¿”å› None
    """
    try:
        # 1. å°è¯•ä»ç¼“å­˜åŠ è½½ï¼ˆä½¿ç”¨å…¬å…±å‡½æ•°ï¼‰
        hist, cache_source = _load_from_cache(symbol, cache_minutes, ignore_expiry=False) if use_cache else (None, None)
        
        # 2. å¦‚æœæ²¡æœ‰ç¼“å­˜æˆ–ç¼“å­˜è¿‡æœŸï¼Œä»APIè·å–ï¼ˆå¸¦æŒ‡æ•°é€€é¿é‡è¯•ï¼‰
        if hist is None:
            # é¿å…è¿‡äºé¢‘ç¹çš„APIè°ƒç”¨
            time.sleep(0.01)
            
            max_retries = 3   # å‡å°‘é‡è¯•æ¬¡æ•°
            base_delay = 0.5  # è°ƒæ•´åŸºç¡€å»¶è¿Ÿ
            
            for attempt in range(max_retries):

                if symbol in broken_stock_symbols:
                    return None
                
                try:
                    # è·å–è¶³å¤Ÿçš„å†å²æ•°æ®ä»¥è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
                    # æ•°æ®è¶Šå¤šï¼ŒEMAè¶Šç¨³å®šã€‚APIè°ƒç”¨æ¬¡æ•°ä¸æ•°æ®é•¿åº¦æ— å…³ï¼Œæ‰€ä»¥å°½å¯èƒ½å¤šè·å–
                    # EMAéœ€è¦è¶³å¤Ÿçš„warmupæœŸæ‰èƒ½ç¨³å®šï¼Œå»ºè®®è‡³å°‘(æ…¢çº¿+ä¿¡å·çº¿)*5 æˆ– 100å¤©ä»¥ä¸Š
                    # å¯¹äºMACD(8,17,9)ï¼š(17+9)*5 = 130å¤©
                    # å¯¹äºMACD(12,26,9)ï¼š(26+9)*5 = 175å¤©
                    # ä½¿ç”¨1yè·å–çº¦250å¤©æ•°æ®ï¼Œç²¾åº¦æœ€ä½³ä¸”APIæ¶ˆè€—ä¸å˜
                    # ä½¿ç”¨ yf.download æ›¿ä»£ stock.historyï¼Œæ”¯æŒ progress=False ç›´æ¥å±è”½è¾“å‡º
                    # auto_adjust=False ä¿æŒä¸ stock.history() é»˜è®¤è¡Œä¸ºä¸€è‡´
                    hist = yf.download(symbol, period="1y", progress=False, auto_adjust=False)
                    
                    # å¤„ç†å¯èƒ½çš„åŒå±‚åˆ—ç´¢å¼•ï¼ˆå•åªè‚¡ç¥¨æ—¶ yf.download å¯èƒ½è¿”å›å¤šå±‚ç´¢å¼•ï¼‰
                    if not hist.empty and isinstance(hist.columns, pd.MultiIndex):
                        hist.columns = hist.columns.droplevel(1)
                    
                    if not hist.empty:
                        cache_source = "API"
                        # æ›´æ–°ç¼“å­˜ï¼ˆå†…å­˜+æ–‡ä»¶ï¼‰
                        if use_cache:
                            now = datetime.now()
                            _DATA_CACHE[symbol] = (now, hist)
                            _save_cache_to_file(symbol, now, hist)
                        break  # æˆåŠŸè·å–ï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                    else:
                        raise Exception("è¿”å›ç©ºæ•°æ®")
                        
                except Exception as api_error:
                    if attempt < max_retries - 1:
                        # æŒ‡æ•°é€€é¿
                        delay = base_delay * (2 ** attempt)
                        print(f"âš ï¸  {symbol} APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {api_error}")
                        time.sleep(delay)
                    else:
                        print(f"âŒ {symbol} APIè°ƒç”¨æœ€ç»ˆå¤±è´¥ (å·²é‡è¯•{max_retries}æ¬¡): {api_error}")
                        return None
        
        # 3. ä½¿ç”¨å†å²æ•°æ®è®¡ç®—æŒ‡æ ‡ï¼ˆå…¬å…±è®¡ç®—é€»è¾‘ï¼‰
        return _calculate_indicators_from_hist(
            hist, symbol, rsi_period, macd_fast, macd_slow,
            macd_signal, avg_volume_days, volume_lut
        )
    
    except KeyboardInterrupt:
        # å…è®¸ç”¨æˆ·ä¸­æ–­
        raise
    except Exception as e:
        print(f"âš ï¸  è·å– {symbol} æ•°æ®æ—¶å‡ºé”™: {e}")
        return None


def get_previous_trading_day_prices(symbol: str):
    """
    è·å–æŒ‡å®šè‚¡ç¥¨ä¸Šä¸€ä¸ªäº¤æ˜“æ—¥çš„å¼€ç›˜ä»·å’Œæ”¶ç›˜ä»·ï¼ˆä¿ç•™å‘åå…¼å®¹ï¼‰
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        
    Returns:
        dict: åŒ…å« symbol, date, open, close çš„å­—å…¸ï¼Œå¤±è´¥è¿”å› None
    """
    data = get_stock_data(symbol)
    if data:
        return {
            'symbol': data['symbol'],
            'date': data['date'],
            'open': data['open'],
            'close': data['close']
        }
    return None


def get_cache_stats():
    """
    è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯ï¼ˆå†…å­˜+æ–‡ä»¶ï¼‰
    
    Returns:
        dict: åŒ…å«ç¼“å­˜ç»Ÿè®¡çš„å­—å…¸
    """
    now = datetime.now()
    stats = {
        'memory_cached': len(_DATA_CACHE),
        'file_cached': 0,
        'symbols': []
    }
    
    # ç»Ÿè®¡æ‰€æœ‰ç¼“å­˜ï¼ˆå†…å­˜+æ–‡ä»¶ï¼‰
    all_symbols = set()
    
    # 1. å†…å­˜ç¼“å­˜
    for symbol in _DATA_CACHE.keys():
        all_symbols.add(symbol)
    
    # 2. æ–‡ä»¶ç¼“å­˜
    for cache_file in CACHE_DIR.glob("*.pkl"):
        symbol = cache_file.stem
        all_symbols.add(symbol)
        stats['file_cached'] += 1
    
    # æ”¶é›†è¯¦ç»†ä¿¡æ¯
    for symbol in sorted(all_symbols):
        info = {'symbol': symbol, 'sources': []}
        
        # æ£€æŸ¥å†…å­˜ç¼“å­˜
        if symbol in _DATA_CACHE:
            cached_time, hist = _DATA_CACHE[symbol]
            age_minutes = (now - cached_time).total_seconds() / 60
            info['sources'].append({
                'type': 'å†…å­˜',
                'age_minutes': age_minutes,
                'data_points': len(hist) if hist != None else 0
            })
        
        # æ£€æŸ¥æ–‡ä»¶ç¼“å­˜
        cache_file = _get_cache_file_path(symbol)
        if cache_file.exists():
            file_cache = _load_cache_from_file(symbol)
            if file_cache:
                cached_time, hist = file_cache
                age_minutes = (now - cached_time).total_seconds() / 60
                info['sources'].append({
                    'type': 'æ–‡ä»¶',
                    'age_minutes': age_minutes,
                    'data_points': len(hist) if hist != None else 0
                })
        
        if info['sources']:
            stats['symbols'].append(info)
    
    return stats


def clear_cache(clear_files=True):
    """
    æ¸…ç©ºæ‰€æœ‰ç¼“å­˜
    
    Args:
        clear_files: æ˜¯å¦åŒæ—¶æ¸…ç©ºæœ¬åœ°ç¼“å­˜æ–‡ä»¶ï¼Œé»˜è®¤ True
    """
    global _DATA_CACHE
    _DATA_CACHE = {}
    
    if clear_files:
        # åˆ é™¤æ‰€æœ‰ç¼“å­˜æ–‡ä»¶
        for cache_file in CACHE_DIR.glob("*.pkl"):
            try:
                cache_file.unlink()
            except Exception as e:
                print(f"åˆ é™¤ç¼“å­˜æ–‡ä»¶å¤±è´¥ {cache_file}: {e}")
        print("å·²æ¸…ç©ºæ‰€æœ‰ç¼“å­˜ï¼ˆå†…å­˜+æ–‡ä»¶ï¼‰")
    else:
        print("å·²æ¸…ç©ºå†…å­˜ç¼“å­˜")
