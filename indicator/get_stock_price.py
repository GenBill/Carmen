import yfinance as yf
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
import pytz
import os
import pickle
from pathlib import Path
import time

from lut import INTRADAY_VOLUME_LUT

# ç¼“å­˜ç›®å½•
CACHE_DIR = Path(__file__).parent / '.cache'
CACHE_DIR.mkdir(exist_ok=True)

# å…¨å±€å†…å­˜ç¼“å­˜ï¼š{symbol: (timestamp, hist_data)}
# åŒæ—¶æ”¯æŒæœ¬åœ°æ–‡ä»¶ç¼“å­˜ï¼Œé¿å…ç¨‹åºé‡å¯åé‡æ–°è·å–æ•°æ®
_DATA_CACHE = {}

# æŸåçš„è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆå¤šæ¬¡å¤±è´¥åä¸å†å°è¯•ï¼‰
broken_stock_symbols = []
try:
    broken_symbols_file = Path(__file__).parent.parent / 'broken_stock_symbols.txt'
    if broken_symbols_file.exists():
        with open(broken_symbols_file, 'r') as f:
            broken_stock_symbols = [line.strip() for line in f if line.strip()]
except:
    broken_stock_symbols = []

def calculate_rsi(prices, period=14, return_series=False):
    """
    è®¡ç®— RSI æŒ‡æ ‡ï¼ˆä½¿ç”¨ Wilder's Smoothing æ–¹æ³•ï¼Œä¸å¯Œé€”ç­‰ä¸»æµå¹³å°ä¸€è‡´ï¼‰
    
    Args:
        prices: ä»·æ ¼åºåˆ—ï¼ˆpandas Seriesï¼‰
        period: RSI å‘¨æœŸï¼Œé»˜è®¤ 14
        return_series: æ˜¯å¦è¿”å›æ•´ä¸ªåºåˆ—ï¼Œé»˜è®¤ Falseï¼ˆåªè¿”å›æœ€åä¸€ä¸ªå€¼ï¼‰
        
    Returns:
        float æˆ– Series: RSI å€¼æˆ–æ•´ä¸ª RSI åºåˆ—
    """
    # è®¡ç®—ä»·æ ¼å˜åŠ¨
    delta = prices.diff()
    
    # åˆ†ç¦»ä¸Šæ¶¨å’Œä¸‹è·Œ
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)
    
    # ä½¿ç”¨ Wilder's Smoothingï¼ˆå¨å°”å¾·å¹³æ»‘æ³•ï¼‰
    # è¿™ç­‰åŒäº EMAï¼Œalpha = 1/period
    # pandas ewm å‚æ•°ï¼šalpha = 1/periodï¼Œadjust=False è¡¨ç¤ºä½¿ç”¨é€’å½’è®¡ç®—
    avg_gain = gain.ewm(alpha=1/period, adjust=False).mean()
    avg_loss = loss.ewm(alpha=1/period, adjust=False).mean()
    
    # è®¡ç®— RS å’Œ RSI
    rs = avg_gain / avg_loss
    rsi = 100 - (100 / (1 + rs))
    
    if return_series:
        return rsi
    else:
        return rsi.iloc[-1] if not pd.isna(rsi.iloc[-1]) else None


def calculate_ema(prices, period, return_series=False):
    """
    è®¡ç®— EMA (æŒ‡æ•°ç§»åŠ¨å¹³å‡çº¿)
    
    Args:
        prices: ä»·æ ¼åºåˆ—ï¼ˆpandas Seriesï¼‰
        period: EMA å‘¨æœŸ
        return_series: æ˜¯å¦è¿”å›æ•´ä¸ªåºåˆ—ï¼Œé»˜è®¤ Falseï¼ˆåªè¿”å›æœ€åä¸€ä¸ªå€¼ï¼‰
        
    Returns:
        float æˆ– Series: EMA å€¼æˆ–æ•´ä¸ª EMA åºåˆ—
    """
    ema = prices.ewm(span=period, adjust=False).mean()
    
    if return_series:
        return ema
    else:
        return ema.iloc[-1] if not pd.isna(ema.iloc[-1]) else None


def calculate_macd(prices, fast=12, slow=26, signal=9):
    """
    è®¡ç®— MACD æŒ‡æ ‡
    
    Args:
        prices: ä»·æ ¼åºåˆ—ï¼ˆpandas Seriesï¼‰
        fast: å¿«çº¿å‘¨æœŸï¼Œé»˜è®¤ 12
        slow: æ…¢çº¿å‘¨æœŸï¼Œé»˜è®¤ 26
        signal: ä¿¡å·çº¿å‘¨æœŸï¼Œé»˜è®¤ 9
        
    Returns:
        dict: åŒ…å« dif(macd), dea(signal), histogram, dif_dea_slope çš„å­—å…¸
    """
    exp1 = prices.ewm(span=fast, adjust=False).mean()
    exp2 = prices.ewm(span=slow, adjust=False).mean()
    dif = exp1 - exp2  # DIFçº¿ï¼ˆå¿«çº¿-æ…¢çº¿ï¼‰
    dea = dif.ewm(span=signal, adjust=False).mean()  # DEAçº¿ï¼ˆDIFçš„ä¿¡å·çº¿ï¼‰
    histogram = dif - dea
    
    # è®¡ç®—DIFæ–œç‡ï¼ˆå½“æ—¥DIF - å‰ä¸€æ—¥DIFï¼‰
    dif_slope, dea_slope, dif_dea_slope = None, None, None
    if len(dif) >= 2 and not pd.isna(dif.iloc[-1]) and not pd.isna(dif.iloc[-2]):
        dif_slope = dif.iloc[-1] - dif.iloc[-2]
    if len(dea) >= 2 and not pd.isna(dea.iloc[-1]) and not pd.isna(dea.iloc[-2]):
        dea_slope = dea.iloc[-1] - dea.iloc[-2]
    if dif_slope != None and dea_slope != None:
        dif_dea_slope = round(dif_slope - dea_slope, 2)
    
    return {
        'dif': round(dif.iloc[-1], 2) if not pd.isna(dif.iloc[-1]) else None,
        'dea': round(dea.iloc[-1], 2) if not pd.isna(dea.iloc[-1]) else None,
        'histogram': round(histogram.iloc[-1], 2) if not pd.isna(histogram.iloc[-1]) else None,
        'dif_dea_slope': dif_dea_slope
    }


def is_intraday_data(trading_date_timestamp):
    """
    åˆ¤æ–­äº¤æ˜“æ—¥æ•°æ®æ˜¯å¦æ˜¯å½“æ—¥ç›˜ä¸­æ•°æ®
    
    Args:
        trading_date_timestamp: äº¤æ˜“æ—¥çš„æ—¶é—´æˆ³ï¼ˆpandas Timestampï¼Œå¸¦æ—¶åŒºï¼‰
        
    Returns:
        tuple: (is_today, current_et_time) - æ˜¯å¦æ˜¯ä»Šå¤©çš„æ•°æ®ï¼Œå½“å‰ç¾ä¸œæ—¶é—´
    """
    et_tz = pytz.timezone('America/New_York')
    
    # å°†äº¤æ˜“æ—¥æ—¶é—´æˆ³è½¬æ¢ä¸ºç¾ä¸œæ—¶é—´
    if trading_date_timestamp.tzinfo is None:
        # å¦‚æœæ²¡æœ‰æ—¶åŒºä¿¡æ¯ï¼Œå‡è®¾æ˜¯UTC
        trading_date_et = trading_date_timestamp.tz_localize('UTC').tz_convert(et_tz)
    else:
        trading_date_et = trading_date_timestamp.tz_convert(et_tz)
    
    # è·å–å½“å‰ç¾ä¸œæ—¶é—´
    current_et = datetime.now(et_tz)
    
    # æå–æ—¥æœŸéƒ¨åˆ†è¿›è¡Œæ¯”è¾ƒ
    trading_date_str = trading_date_et.strftime('%Y-%m-%d')
    current_date_str = current_et.strftime('%Y-%m-%d')
    
    is_today = (trading_date_str == current_date_str)
    
    return is_today, current_et

def is_market_time(current_et_time):
    """
    æ£€æŸ¥å½“å‰ETæ—¶é—´æ˜¯å¦åœ¨ç¾è‚¡äº¤æ˜“æ—¶é—´å†…ï¼ˆ9:30-16:00 ETï¼Œå…¨å¹´å›ºå®šï¼‰ã€‚
    
    Args:
        current_et_time (datetime): å·²è½¬æ¢ä¸ºETçš„datetimeå¯¹è±¡ï¼ˆæ— æ—¶åŒºæˆ–å¸¦ETæ—¶åŒºï¼‰ã€‚
    
    Returns:
        bool: æ˜¯å¦åœ¨äº¤æ˜“æ—¶é—´å†…ã€‚
    """
    # ç¾è‚¡äº¤æ˜“æ—¶é—´å›ºå®šä¸ºET 9:30-16:00ï¼ˆä¸å«å‘¨æœ«/å‡æœŸï¼Œæ­¤å‡½æ•°ä»…æŸ¥æ—¶é—´ï¼‰
    current_time_minutes = current_et_time.hour * 60 + current_et_time.minute
    market_open = 9 * 60 + 30
    market_close = 16 * 60
    
    return market_open <= current_time_minutes < market_close  # æ³¨æ„ï¼šæ”¶ç›˜ä¸å«16:00æœ¬èº«ï¼Œè‹¥éœ€å«å¯æ”¹<=

def estimate_full_day_volume(current_volume, trading_date_timestamp, volume_lut=None):
    """
    æ ¹æ®ç›˜ä¸­å½“å‰æ—¶é—´å’Œæˆäº¤é‡ä¼°ç®—å…¨å¤©æˆäº¤é‡
    åªåœ¨ç¡®è®¤æ˜¯å½“æ—¥ç›˜ä¸­æ•°æ®æ—¶æ‰ä¼°ç®—ï¼Œå¦åˆ™è¿”å›åŸå€¼
    
    Args:
        current_volume: å½“å‰æˆäº¤é‡
        trading_date_timestamp: äº¤æ˜“æ—¥çš„æ—¶é—´æˆ³ï¼ˆpandas Timestampï¼‰
        volume_lut: æˆäº¤é‡LUTè¡¨ï¼ŒNoneåˆ™ä½¿ç”¨é»˜è®¤è¡¨
        
    Returns:
        int: ä¼°ç®—çš„å…¨å¤©æˆäº¤é‡ï¼Œå¦‚æœä¸æ˜¯ç›˜ä¸­æ•°æ®åˆ™è¿”å›åŸå€¼
    """
    # åˆ¤æ–­æ˜¯å¦æ˜¯å½“æ—¥ç›˜ä¸­æ•°æ®
    is_today, current_et_time = is_intraday_data(trading_date_timestamp)
    
    if not is_today:
        # ä¸æ˜¯ä»Šå¤©çš„æ•°æ®ï¼Œç›´æ¥è¿”å›åŸå€¼ï¼ˆè¿™æ˜¯å·²æ”¶ç›˜çš„å®Œæ•´æ•°æ®ï¼‰
        return current_volume
    
    if not is_market_time(current_et_time):
        # ä¸åœ¨äº¤æ˜“æ—¶é—´å†…ï¼Œè¿”å›åŸå€¼
        return current_volume
    
    # åœ¨ç›˜ä¸­ï¼Œè¿›è¡Œä¼°ç®—
    if volume_lut is None:
        volume_lut = INTRADAY_VOLUME_LUT
    
    current_time_str = current_et_time.strftime('%H:%M')
    
    # æŸ¥æ‰¾æœ€æ¥è¿‘çš„æ—¶é—´ç‚¹
    time_keys = sorted(volume_lut.keys())
    selected_ratio = None
    
    for time_key in time_keys:
        if current_time_str <= time_key:
            selected_ratio = volume_lut[time_key]
            break
    
    # å¦‚æœå½“å‰æ—¶é—´è¶…è¿‡æœ€åä¸€ä¸ªæ—¶é—´ç‚¹ï¼Œä½¿ç”¨1.0
    if selected_ratio is None:
        selected_ratio = 1.0
    
    # é¿å…é™¤ä»¥0
    if selected_ratio > 0:
        estimated_volume = int(current_volume / selected_ratio)
        return estimated_volume
    else:
        return current_volume


def _get_cache_file_path(symbol: str) -> Path:
    """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
    return CACHE_DIR / f"{symbol}.pkl"


def _load_cache_from_file(symbol: str):
    """ä»æœ¬åœ°æ–‡ä»¶åŠ è½½ç¼“å­˜"""
    cache_file = _get_cache_file_path(symbol)
    if cache_file.exists():
        try:
            with open(cache_file, 'rb') as f:
                cached_time, hist_data = pickle.load(f)
                return cached_time, hist_data
        except Exception as e:
            print(f"åŠ è½½ç¼“å­˜æ–‡ä»¶å¤±è´¥ {symbol}: {e}")
            return None
    return None


def _save_cache_to_file(symbol: str, cached_time, hist_data):
    """ä¿å­˜ç¼“å­˜åˆ°æœ¬åœ°æ–‡ä»¶"""
    cache_file = _get_cache_file_path(symbol)
    try:
        with open(cache_file, 'wb') as f:
            pickle.dump((cached_time, hist_data), f)
    except Exception as e:
        print(f"ä¿å­˜ç¼“å­˜æ–‡ä»¶å¤±è´¥ {symbol}: {e}")


def _is_cache_valid_smart(cached_time, cached_hist, cache_minutes, ignore_expiry=False):
    """
    æ™ºèƒ½ç¼“å­˜æœ‰æ•ˆæ€§æ£€æŸ¥ï¼ˆåŸºäºæ•°æ®æœ€æ–°æ—¥æœŸå’Œå¸‚åœºçŠ¶æ€ï¼‰
    
    æ ¸å¿ƒæ€æƒ³ï¼š
    - è‚¡ç¥¨ä»·æ ¼åªåœ¨ç›˜ä¸­å˜åŒ–
    - ç¼“å­˜åº”è¯¥åŸºäº"æ•°æ®çš„æœ€æ–°äº¤æ˜“æ—¥"è€Œä¸æ˜¯"ç¼“å­˜ä¿å­˜æ—¶é—´"
    
    Args:
        cached_time: ç¼“å­˜ä¿å­˜æ—¶é—´
        cached_hist: ç¼“å­˜çš„å†å²æ•°æ®
        cache_minutes: ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆåˆ†é’Ÿï¼‰
        ignore_expiry: æ˜¯å¦å¿½ç•¥è¿‡æœŸï¼ˆç¦»çº¿æ¨¡å¼ï¼‰
        
    Returns:
        bool: ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
    """
    if ignore_expiry:
        return True
    
    now = datetime.now()
    et_tz = pytz.timezone('America/New_York')
    
    # å°†ç¼“å­˜æ—¶é—´è½¬æ¢ä¸ºç¾ä¸œæ—¶é—´
    if cached_time.tzinfo is None:
        cached_time_et = pytz.utc.localize(cached_time).astimezone(et_tz)
    else:
        cached_time_et = cached_time.astimezone(et_tz)
    
    current_et = datetime.now(et_tz)
    
    # åˆ¤æ–­ç¼“å­˜ä¿å­˜æ—¶é—´æ˜¯å¦åœ¨ç›˜ä¸­ï¼ˆ9:30-16:30 ETï¼Œå«ç›˜å30åˆ†é’Ÿç¼“å†²æœŸï¼‰
    cached_hour_minute = cached_time_et.hour * 60 + cached_time_et.minute
    market_open = 9 * 60 + 30   # 9:30
    market_close = 16 * 60 + 30  # 16:30ï¼ˆç›˜å30åˆ†é’Ÿç¼“å†²ï¼Œå› APIæœ‰5-10åˆ†é’Ÿå»¶è¿Ÿï¼‰
    was_cached_during_market = market_open <= cached_hour_minute < market_close
    
    # å¦‚æœç¼“å­˜æ—¶é—´æˆ³åœ¨ç›˜ä¸­ï¼Œä½¿ç”¨ä¼ ç»Ÿçš„æ—¶é—´åˆ¤æ–­ï¼ˆçŸ­ç¼“å­˜ï¼‰
    if was_cached_during_market:
        cache_age_minutes = (now - cached_time).total_seconds() / 60
        return cache_age_minutes < cache_minutes
    
    # å¦‚æœç¼“å­˜æ—¶é—´æˆ³ä¸åœ¨ç›˜ä¸­ï¼ˆç›˜å‰/ç›˜å/å‘¨æœ«ï¼‰ï¼Œæ£€æŸ¥æ•°æ®çš„æœ€æ–°æ—¥æœŸ
    if cached_hist is None or cached_hist.empty:
        return False
    
    # è·å–ç¼“å­˜æ•°æ®çš„æœ€åäº¤æ˜“æ—¥
    last_data_date = cached_hist.index[-1]
    if last_data_date.tzinfo is None:
        last_data_date_et = pytz.utc.localize(last_data_date).astimezone(et_tz)
    else:
        last_data_date_et = last_data_date.astimezone(et_tz)
    
    # åˆ¤æ–­å½“å‰æ˜¯å¦åœ¨ç›˜ä¸­ï¼ˆå«ç›˜å30åˆ†é’Ÿç¼“å†²æœŸï¼‰
    current_hour_minute = current_et.hour * 60 + current_et.minute
    is_market_open_now = (market_open <= current_hour_minute < market_close and 
                          current_et.weekday() < 5)
    
    if is_market_open_now:
        # å½“å‰åœ¨ç›˜ä¸­ï¼Œéœ€è¦å®æ—¶æ•°æ®
        # æ£€æŸ¥æ•°æ®æ˜¯å¦æ˜¯ä»Šå¤©çš„ï¼Œä¸”ç¼“å­˜ä¸è¶…è¿‡æŒ‡å®šæ—¶é—´
        current_date = current_et.date()
        last_data_only_date = last_data_date_et.date()
        
        if last_data_only_date >= current_date:
            # æ•°æ®æ˜¯ä»Šå¤©çš„ï¼Œæ£€æŸ¥ç¼“å­˜å¹´é¾„
            cache_age_minutes = (now - cached_time).total_seconds() / 60
            return cache_age_minutes < cache_minutes
        else:
            # æ•°æ®ä¸æ˜¯ä»Šå¤©çš„ï¼Œéœ€è¦åˆ·æ–°
            return False
    else:
        # å½“å‰ä¸åœ¨ç›˜ä¸­ï¼ˆç›˜å‰/ç›˜å/å‘¨æœ«ï¼‰ï¼Œåªéœ€è¦æœ€æ–°äº¤æ˜“æ—¥æ•°æ®
        # è®¡ç®—æ•°æ®è·ä»Šå¤©æ•°
        days_old = (current_et.date() - last_data_date_et.date()).days
        
        # å¦‚æœæ•°æ®æ˜¯æœ€è¿‘2å¤©å†…çš„ï¼Œè®¤ä¸ºæœ‰æ•ˆï¼ˆè€ƒè™‘å‘¨æœ«å’ŒèŠ‚å‡æ—¥ï¼‰
        return days_old <= 2


def _load_from_cache(symbol: str, cache_minutes=5, ignore_expiry=False):
    """
    ä»ç¼“å­˜åŠ è½½æ•°æ®ï¼ˆå…¬å…±å‡½æ•°ï¼‰
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        cache_minutes: ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆåˆ†é’Ÿï¼‰
        ignore_expiry: æ˜¯å¦å¿½ç•¥è¿‡æœŸæ—¶é—´ï¼ˆç¦»çº¿æ¨¡å¼ç”¨ï¼‰
        
    Returns:
        tuple: (hist_data, cache_source) æˆ– (None, None)
    """
    now = datetime.now()
    cache_key = symbol
    
    # 1. æ£€æŸ¥å†…å­˜ç¼“å­˜
    if cache_key in _DATA_CACHE:
        cached_time, cached_hist = _DATA_CACHE[cache_key]
        
        if _is_cache_valid_smart(cached_time, cached_hist, cache_minutes, ignore_expiry):
            return cached_hist, "å†…å­˜"
    
    # 2. æ£€æŸ¥æ–‡ä»¶ç¼“å­˜
    file_cache = _load_cache_from_file(symbol)
    if file_cache:
        cached_time, cached_hist = file_cache
        
        if _is_cache_valid_smart(cached_time, cached_hist, cache_minutes, ignore_expiry):
            # åŠ è½½åˆ°å†…å­˜ç¼“å­˜
            _DATA_CACHE[cache_key] = (cached_time, cached_hist)
            return cached_hist, "æ–‡ä»¶"
    
    return None, None


def _calculate_indicators_from_hist(hist, symbol, rsi_period, macd_fast, macd_slow, 
                                    macd_signal, avg_volume_days, volume_lut):
    """
    ä»å†å²æ•°æ®è®¡ç®—æ‰€æœ‰æŒ‡æ ‡ï¼ˆå…¬å…±è®¡ç®—é€»è¾‘ï¼‰
    
    Args:
        hist: å†å²æ•°æ®DataFrame
        symbol: è‚¡ç¥¨ä»£ç 
        å…¶ä»–å‚æ•°: æŠ€æœ¯æŒ‡æ ‡å‚æ•°
        
    Returns:
        dict: åŒ…å«æ‰€æœ‰è®¡ç®—ç»“æœçš„å­—å…¸
    """
    if hist.empty or len(hist) < avg_volume_days + 1:
        return None
    
    # è·å–æœ€åä¸€ä¸ªäº¤æ˜“æ—¥æ•°æ®ï¼ˆå½“æ—¥æˆ–æœ€è¿‘äº¤æ˜“æ—¥ï¼‰
    last_trading_day = hist.iloc[-1]
    trading_date_timestamp = hist.index[-1]
    trading_date = trading_date_timestamp.strftime('%Y-%m-%d')
    
    # è®¡ç®—è¿‡å» N æ—¥å¹³å‡æˆäº¤é‡ï¼ˆæ˜ç¡®æ’é™¤å½“æ—¥ï¼Œå³æœ€åä¸€ä¸ªäº¤æ˜“æ—¥ï¼‰
    if len(hist) >= avg_volume_days + 1:
        avg_volume = hist.iloc[-(avg_volume_days+1):-1]['Volume'].mean()
    else:
        avg_volume = hist.iloc[:-1]['Volume'].mean()
    
    # å½“æ—¥æˆäº¤é‡
    current_volume = last_trading_day['Volume']
    
    # ä¼°ç®—å…¨å¤©æˆäº¤é‡ï¼ˆåªåœ¨ç¡®è®¤æ˜¯å½“æ—¥ç›˜ä¸­æ•°æ®æ—¶æ‰ä¼°ç®—ï¼‰
    estimated_volume = estimate_full_day_volume(current_volume, trading_date_timestamp, volume_lut=volume_lut)
    
    # è®¡ç®— RSIï¼ˆè·å–å®Œæ•´åºåˆ—ä»¥ä¾¿æå–å‰ä¸€æ—¥æ•°æ®ï¼‰
    rsi_series = calculate_rsi(hist['Close'], period=rsi_period, return_series=True)
    rsi = rsi_series.iloc[-1] if not pd.isna(rsi_series.iloc[-1]) else None
    rsi_prev = None
    if len(rsi_series) >= 2 and not pd.isna(rsi_series.iloc[-2]):
        rsi_prev = rsi_series.iloc[-2]
    
    # è®¡ç®— MACD
    macd_data = calculate_macd(hist['Close'], fast=macd_fast, slow=macd_slow, signal=macd_signal)
    
    # è®¡ç®— EMA æŒ‡æ ‡ï¼ˆè·å–å®Œæ•´åºåˆ—ä»¥ä¾¿æå–å‰ä¸€æ—¥æ•°æ®ï¼‰
    ema_12_series = calculate_ema(hist['Close'], period=12, return_series=True)
    ema_144_series = calculate_ema(hist['Close'], period=144, return_series=True)
    
    ema_12 = ema_12_series.iloc[-1] if not pd.isna(ema_12_series.iloc[-1]) else None
    ema_144 = ema_144_series.iloc[-1] if not pd.isna(ema_144_series.iloc[-1]) else None
    
    # è·å–å‰ä¸€æ—¥ EMA æ•°æ®
    ema_12_prev = None
    ema_144_prev = None
    if len(ema_12_series) >= 2 and not pd.isna(ema_12_series.iloc[-2]):
        ema_12_prev = ema_12_series.iloc[-2]
    if len(ema_144_series) >= 2 and not pd.isna(ema_144_series.iloc[-2]):
        ema_144_prev = ema_144_series.iloc[-2]
    
    return {
        'symbol': symbol,
        'date': trading_date,
        'open': round(last_trading_day['Open'], 2),
        'close': round(last_trading_day['Close'], 2),
        'volume': int(current_volume),
        'estimated_volume': estimated_volume,
        'avg_volume': int(avg_volume),
        'rsi': round(rsi, 2) if rsi else None,
        'rsi_prev': round(rsi_prev, 2) if rsi_prev else None,
        'dif': macd_data['dif'],
        'dea': macd_data['dea'],
        'macd_histogram': macd_data['histogram'],
        'dif_dea_slope': macd_data['dif_dea_slope'],
        'ema_12': round(ema_12, 2) if ema_12 else None,
        'ema_144': round(ema_144, 2) if ema_144 else None,
        'ema_12_prev': round(ema_12_prev, 2) if ema_12_prev else None,
        'ema_144_prev': round(ema_144_prev, 2) if ema_144_prev else None
    }


def get_stock_data_offline(symbol: str, rsi_period=14, macd_fast=12, macd_slow=26, macd_signal=9, 
                           avg_volume_days=8, volume_lut=None, use_cache=True, cache_minutes=5):
    """
    ç¦»çº¿æ¨¡å¼ï¼šä»…ä»ç¼“å­˜è¯»å–æ•°æ®ï¼Œä¸è°ƒç”¨APIï¼ˆå¿½ç•¥ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼‰
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        rsi_period: RSI å‘¨æœŸï¼Œé»˜è®¤ 14
        macd_fast: MACD å¿«çº¿å‘¨æœŸï¼Œé»˜è®¤ 12
        macd_slow: MACD æ…¢çº¿å‘¨æœŸï¼Œé»˜è®¤ 26
        macd_signal: MACD ä¿¡å·çº¿å‘¨æœŸï¼Œé»˜è®¤ 9
        avg_volume_days: å¹³å‡æˆäº¤é‡è®¡ç®—å¤©æ•°ï¼Œé»˜è®¤ 8
        volume_lut: è‡ªå®šä¹‰æˆäº¤é‡ä¼°ç®—LUTè¡¨ï¼ŒNoneåˆ™ä½¿ç”¨é»˜è®¤è¡¨
        use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜ï¼ˆç¦»çº¿æ¨¡å¼å›ºå®šä¸ºTrueï¼‰
        cache_minutes: å¿½ç•¥ï¼ˆç¦»çº¿æ¨¡å¼ä¸æ£€æŸ¥è¿‡æœŸï¼‰
        
    Returns:
        dict: åŒ…å«æ‰€æœ‰æ•°æ®çš„å­—å…¸ï¼Œç¼“å­˜ä¸å­˜åœ¨è¿”å› None
    """
    try:
        # ä»ç¼“å­˜åŠ è½½ï¼ˆå¿½ç•¥è¿‡æœŸæ—¶é—´ï¼‰
        hist, cache_source = _load_from_cache(symbol, cache_minutes=0, ignore_expiry=True)
        
        if hist is None:
            # ç¦»çº¿æ¨¡å¼ä¸‹ç¼“å­˜ä¸å­˜åœ¨åˆ™è¿”å›None
            return None
        
        # ä½¿ç”¨å†å²æ•°æ®è®¡ç®—æŒ‡æ ‡ï¼ˆå…¬å…±è®¡ç®—é€»è¾‘ï¼‰
        return _calculate_indicators_from_hist(
            hist, symbol, rsi_period, macd_fast, macd_slow,
            macd_signal, avg_volume_days, volume_lut
        )
    except KeyboardInterrupt:
        raise
    except Exception as e:
        print(f"âš ï¸  ç¦»çº¿æ¨¡å¼è·å– {symbol} æ•°æ®æ—¶å‡ºé”™: {e}")
        return None

def get_stock_data(symbol: str, rsi_period=14, macd_fast=12, macd_slow=26, macd_signal=9, 
                   avg_volume_days=8, volume_lut=None, use_cache=True, cache_minutes=5):
    """
    è·å–è‚¡ç¥¨çš„å…¨é¢æ•°æ®ï¼ŒåŒ…æ‹¬ä»·æ ¼ã€æˆäº¤é‡å’ŒæŠ€æœ¯æŒ‡æ ‡
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        rsi_period: RSI å‘¨æœŸï¼Œé»˜è®¤ 14
        macd_fast: MACD å¿«çº¿å‘¨æœŸï¼Œé»˜è®¤ 12
        macd_slow: MACD æ…¢çº¿å‘¨æœŸï¼Œé»˜è®¤ 26
        macd_signal: MACD ä¿¡å·çº¿å‘¨æœŸï¼Œé»˜è®¤ 9
        avg_volume_days: å¹³å‡æˆäº¤é‡è®¡ç®—å¤©æ•°ï¼Œé»˜è®¤ 8
        volume_lut: è‡ªå®šä¹‰æˆäº¤é‡ä¼°ç®—LUTè¡¨ï¼ŒNoneåˆ™ä½¿ç”¨é»˜è®¤è¡¨
        use_cache: æ˜¯å¦ä½¿ç”¨æœ¬åœ°ç¼“å­˜ï¼Œé»˜è®¤ True
        cache_minutes: ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆåˆ†é’Ÿï¼‰ï¼Œé»˜è®¤ 5åˆ†é’Ÿ
        offline_mode: æ˜¯å¦ç¦»çº¿æ¨¡å¼ï¼Œé»˜è®¤ False
        
    Returns:
        dict: åŒ…å«æ‰€æœ‰æ•°æ®çš„å­—å…¸ï¼Œå¤±è´¥è¿”å› None
    """
    try:
        # 1. å°è¯•ä»ç¼“å­˜åŠ è½½ï¼ˆä½¿ç”¨å…¬å…±å‡½æ•°ï¼‰
        hist, cache_source = _load_from_cache(symbol, cache_minutes, ignore_expiry=False) if use_cache else (None, None)
        
        # 2. å¦‚æœæ²¡æœ‰ç¼“å­˜æˆ–ç¼“å­˜è¿‡æœŸï¼Œä»APIè·å–ï¼ˆå¸¦æŒ‡æ•°é€€é¿é‡è¯•ï¼‰
        if hist is None:
            # é¿å…è¿‡äºé¢‘ç¹çš„APIè°ƒç”¨
            time.sleep(0.1)
            
            max_retries = 4   # æœ€å¤šé‡è¯•4æ¬¡
            base_delay = 2    # åŸºç¡€å»¶è¿Ÿ2ç§’
            
            for attempt in range(max_retries):

                if symbol in broken_stock_symbols:
                    return None
                
                try:
                    stock = yf.Ticker(symbol)
                    
                    # è·å–è¶³å¤Ÿçš„å†å²æ•°æ®ä»¥è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
                    # æ•°æ®è¶Šå¤šï¼ŒEMAè¶Šç¨³å®šã€‚APIè°ƒç”¨æ¬¡æ•°ä¸æ•°æ®é•¿åº¦æ— å…³ï¼Œæ‰€ä»¥å°½å¯èƒ½å¤šè·å–
                    # EMAéœ€è¦è¶³å¤Ÿçš„warmupæœŸæ‰èƒ½ç¨³å®šï¼Œå»ºè®®è‡³å°‘(æ…¢çº¿+ä¿¡å·çº¿)*5 æˆ– 100å¤©ä»¥ä¸Š
                    # å¯¹äºMACD(8,17,9)ï¼š(17+9)*5 = 130å¤©
                    # å¯¹äºMACD(12,26,9)ï¼š(26+9)*5 = 175å¤©
                    # ä½¿ç”¨1yè·å–çº¦250å¤©æ•°æ®ï¼Œç²¾åº¦æœ€ä½³ä¸”APIæ¶ˆè€—ä¸å˜
                    hist = stock.history(period="1y", timeout=10)
                    
                    if not hist.empty:
                        cache_source = "API"
                        # æ›´æ–°ç¼“å­˜ï¼ˆå†…å­˜+æ–‡ä»¶ï¼‰
                        if use_cache:
                            now = datetime.now()
                            _DATA_CACHE[symbol] = (now, hist)
                            _save_cache_to_file(symbol, now, hist)
                        break  # æˆåŠŸè·å–ï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                    else:
                        raise Exception("è¿”å›ç©ºæ•°æ®")
                        
                except Exception as api_error:
                    error_str = str(api_error).lower()
                    error_type = type(api_error).__name__
                    
                    # åˆ†ç±»é”™è¯¯ç±»å‹
                    # 1. è‚¡ç¥¨æ— æ•ˆ/ä¸å­˜åœ¨ - ä¸é‡è¯•
                    invalid_stock_indicators = [
                        "expecting value",      # JSONè§£æå¤±è´¥ï¼Œé€šå¸¸æ˜¯ç©ºå“åº”
                        "no data found",        # yfinanceæ˜ç¡®è¿”å›æ— æ•°æ®
                        "no price data found",  # æ— ä»·æ ¼æ•°æ®
                        "404",                  # HTTP 404
                        "not found"             # è‚¡ç¥¨æœªæ‰¾åˆ°
                    ]
                    
                    # 2. APIé™æµ/æœåŠ¡å™¨é—®é¢˜ - åº”è¯¥é‡è¯•
                    rate_limit_indicators = [
                        "429",                  # HTTP 429 Too Many Requests
                        "too many requests",    # é™æµ
                        "rate limit",           # é€Ÿç‡é™åˆ¶
                        "503",                  # Service Unavailable
                        "502",                  # Bad Gateway
                        "500"                   # Internal Server Error
                    ]
                    
                    # 3. ç½‘ç»œé—®é¢˜ - åº”è¯¥é‡è¯•
                    network_indicators = [
                        "timeout",              # è¶…æ—¶
                        "connection",           # è¿æ¥é—®é¢˜
                        "unable to connect",    # æ— æ³•è¿æ¥
                        "network"               # ç½‘ç»œé”™è¯¯
                    ]
                    
                    # åˆ¤æ–­é”™è¯¯ç±»å‹
                    is_invalid_stock = any(indicator in error_str for indicator in invalid_stock_indicators)
                    is_rate_limit = any(indicator in error_str for indicator in rate_limit_indicators)
                    is_network = any(indicator in error_str for indicator in network_indicators)
                    
                    # è‚¡ç¥¨æ— æ•ˆ - ç›´æ¥å¤±è´¥ï¼Œä¸é‡è¯•
                    if is_invalid_stock:
                        print(f"âŒ {symbol} è‚¡ç¥¨ä»£ç æ— æ•ˆæˆ–å·²é€€å¸‚: {api_error}")
                        return None
                    
                    # APIé™æµ - éœ€è¦æ›´é•¿çš„ç­‰å¾…æ—¶é—´
                    if is_rate_limit:
                        if attempt < max_retries - 1:
                            # APIé™æµæ—¶ä½¿ç”¨æ›´é•¿çš„å»¶è¿Ÿï¼š5ç§’, 10ç§’, 20ç§’
                            delay = 5 * (2 ** attempt)
                            print(f"âš ï¸  {symbol} APIé™æµ (å°è¯• {attempt + 1}/{max_retries})")
                            print(f"   ğŸ• ç­‰å¾… {delay} ç§’åé‡è¯•...")
                            time.sleep(delay)
                        else:
                            print(f"âŒ {symbol} APIé™æµæŒç»­ï¼Œå·²æ”¾å¼ƒ (é‡è¯•{max_retries}æ¬¡)")
                            return None
                    
                    # ç½‘ç»œé—®é¢˜æˆ–å…¶ä»–ä¸´æ—¶é”™è¯¯ - æ­£å¸¸é‡è¯•
                    elif is_network or attempt < max_retries - 1:
                        delay = base_delay * (2 ** attempt)
                        error_category = "ç½‘ç»œé”™è¯¯" if is_network else "APIé”™è¯¯"
                        print(f"âš ï¸  {symbol} {error_category} (å°è¯• {attempt + 1}/{max_retries}): {api_error}")
                        print(f"   ç­‰å¾… {delay} ç§’åé‡è¯•...")
                        time.sleep(delay)
                    else:
                        # æœ€åä¸€æ¬¡å°è¯•ä¹Ÿå¤±è´¥
                        print(f"âŒ {symbol} APIè°ƒç”¨æœ€ç»ˆå¤±è´¥ (å·²é‡è¯•{max_retries}æ¬¡): {api_error}")
                        return None
        
        # 3. ä½¿ç”¨å†å²æ•°æ®è®¡ç®—æŒ‡æ ‡ï¼ˆå…¬å…±è®¡ç®—é€»è¾‘ï¼‰
        return _calculate_indicators_from_hist(
            hist, symbol, rsi_period, macd_fast, macd_slow,
            macd_signal, avg_volume_days, volume_lut
        )
    
    except KeyboardInterrupt:
        # å…è®¸ç”¨æˆ·ä¸­æ–­
        raise
    except Exception as e:
        print(f"âš ï¸  è·å– {symbol} æ•°æ®æ—¶å‡ºé”™: {e}")
        return None


def get_previous_trading_day_prices(symbol: str):
    """
    è·å–æŒ‡å®šè‚¡ç¥¨ä¸Šä¸€ä¸ªäº¤æ˜“æ—¥çš„å¼€ç›˜ä»·å’Œæ”¶ç›˜ä»·ï¼ˆä¿ç•™å‘åå…¼å®¹ï¼‰
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        
    Returns:
        dict: åŒ…å« symbol, date, open, close çš„å­—å…¸ï¼Œå¤±è´¥è¿”å› None
    """
    data = get_stock_data(symbol)
    if data:
        return {
            'symbol': data['symbol'],
            'date': data['date'],
            'open': data['open'],
            'close': data['close']
        }
    return None


def get_cache_stats():
    """
    è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯ï¼ˆå†…å­˜+æ–‡ä»¶ï¼‰
    
    Returns:
        dict: åŒ…å«ç¼“å­˜ç»Ÿè®¡çš„å­—å…¸
    """
    now = datetime.now()
    stats = {
        'memory_cached': len(_DATA_CACHE),
        'file_cached': 0,
        'symbols': []
    }
    
    # ç»Ÿè®¡æ‰€æœ‰ç¼“å­˜ï¼ˆå†…å­˜+æ–‡ä»¶ï¼‰
    all_symbols = set()
    
    # 1. å†…å­˜ç¼“å­˜
    for symbol in _DATA_CACHE.keys():
        all_symbols.add(symbol)
    
    # 2. æ–‡ä»¶ç¼“å­˜
    for cache_file in CACHE_DIR.glob("*.pkl"):
        symbol = cache_file.stem
        all_symbols.add(symbol)
        stats['file_cached'] += 1
    
    # æ”¶é›†è¯¦ç»†ä¿¡æ¯
    for symbol in sorted(all_symbols):
        info = {'symbol': symbol, 'sources': []}
        
        # æ£€æŸ¥å†…å­˜ç¼“å­˜
        if symbol in _DATA_CACHE:
            cached_time, hist = _DATA_CACHE[symbol]
            age_minutes = (now - cached_time).total_seconds() / 60
            info['sources'].append({
                'type': 'å†…å­˜',
                'age_minutes': age_minutes,
                'data_points': len(hist) if hist != None else 0
            })
        
        # æ£€æŸ¥æ–‡ä»¶ç¼“å­˜
        cache_file = _get_cache_file_path(symbol)
        if cache_file.exists():
            file_cache = _load_cache_from_file(symbol)
            if file_cache:
                cached_time, hist = file_cache
                age_minutes = (now - cached_time).total_seconds() / 60
                info['sources'].append({
                    'type': 'æ–‡ä»¶',
                    'age_minutes': age_minutes,
                    'data_points': len(hist) if hist != None else 0
                })
        
        if info['sources']:
            stats['symbols'].append(info)
    
    return stats


def clear_cache(clear_files=True):
    """
    æ¸…ç©ºæ‰€æœ‰ç¼“å­˜
    
    Args:
        clear_files: æ˜¯å¦åŒæ—¶æ¸…ç©ºæœ¬åœ°ç¼“å­˜æ–‡ä»¶ï¼Œé»˜è®¤ True
    """
    global _DATA_CACHE
    _DATA_CACHE = {}
    
    if clear_files:
        # åˆ é™¤æ‰€æœ‰ç¼“å­˜æ–‡ä»¶
        for cache_file in CACHE_DIR.glob("*.pkl"):
            try:
                cache_file.unlink()
            except Exception as e:
                print(f"åˆ é™¤ç¼“å­˜æ–‡ä»¶å¤±è´¥ {cache_file}: {e}")
        print("å·²æ¸…ç©ºæ‰€æœ‰ç¼“å­˜ï¼ˆå†…å­˜+æ–‡ä»¶ï¼‰")
    else:
        print("å·²æ¸…ç©ºå†…å­˜ç¼“å­˜")
